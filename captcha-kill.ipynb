{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import callbacks\n",
    "import os\n",
    "import cv2\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = string.ascii_lowercase + '0123456789'\n",
    "num_symbols = len(symbols)\n",
    "img_shape = (50,200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    n_samples = len(os.listdir('samples/'))\n",
    "    X = np.zeros((n_samples,50,200,1))\n",
    "    y = np.zeros((5,n_samples,num_symbols))\n",
    "    \n",
    "    for i, pic in enumerate(os.listdir('samples/')):\n",
    "        img = cv2.imread(os.path.join('samples/',pic),cv2.IMREAD_GRAYSCALE)\n",
    "        pic_target = pic[:-4]\n",
    "        if len(pic_target) < 6:\n",
    "            img = img/255.0\n",
    "            img = np.reshape(img,(50,200,1))\n",
    "            targs = np.zeros((5,num_symbols))\n",
    "            for j,l in enumerate(pic_target):\n",
    "                ind = symbols.find(l)\n",
    "                targs[j,ind] = 1\n",
    "            X[i] = img\n",
    "            y[:,i]=targs\n",
    "    return X,y\n",
    "\n",
    "X,y = preprocess_data()\n",
    "X_train, y_train = X[:970],y[:,:970]\n",
    "X_test, y_test = X[970:],y[:,970:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    img = layers.Input(shape=img_shape)\n",
    "    conv1 = layers.Conv2D(16,(3,3),padding='same',activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)\n",
    "    conv2 = layers.Conv2D(32,(3,3),padding='same',activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(mp1)\n",
    "    conv3 = layers.Conv2D(32,(3,3),padding = 'same',activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)\n",
    "    \n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64,activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols,activation='sigmoid')(drop)\n",
    "        \n",
    "        outs.append(res)\n",
    "        \n",
    "    model = Model(img,outs)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 21:20:09.657624  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 21:20:09.671616  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 21:20:09.675576  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 21:20:09.687575  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0829 21:20:09.727470  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 21:20:09.728468  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0829 21:20:11.841621  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0829 21:20:11.943326  8528 deprecation.py:506] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 21:20:12.128829  8528 deprecation_wrapper.py:119] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50, 200, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 50, 200, 16)  160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 100, 16)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 50, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 13, 50, 32)   4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 13, 50, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 25, 32)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5600)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           358464      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           358464      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           358464      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           358464      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           358464      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 36)           2340        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 36)           2340        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 36)           2340        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 36)           2340        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 36)           2340        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,808,948\n",
      "Trainable params: 1,808,884\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 21:20:16.586280  8528 deprecation.py:323] From C:\\Users\\hp\\.conda\\envs\\tensor_test\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 11s 14ms/step - loss: 17.3904 - dense_2_loss: 3.4135 - dense_4_loss: 3.4778 - dense_6_loss: 3.4341 - dense_8_loss: 3.4733 - dense_10_loss: 3.5917 - dense_2_acc: 0.0838 - dense_4_acc: 0.0657 - dense_6_acc: 0.0696 - dense_8_acc: 0.0399 - dense_10_acc: 0.0387 - val_loss: 16.2329 - val_dense_2_loss: 3.3963 - val_dense_4_loss: 3.2109 - val_dense_6_loss: 3.0602 - val_dense_8_loss: 3.1872 - val_dense_10_loss: 3.3783 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.0309 - val_dense_6_acc: 0.0979 - val_dense_8_acc: 0.0361 - val_dense_10_acc: 0.0567\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 15.8828 - dense_2_loss: 3.0598 - dense_4_loss: 3.1887 - dense_6_loss: 3.1672 - dense_8_loss: 3.1609 - dense_10_loss: 3.3062 - dense_2_acc: 0.0863 - dense_4_acc: 0.0709 - dense_6_acc: 0.0812 - dense_8_acc: 0.0619 - dense_10_acc: 0.0490 - val_loss: 16.3091 - val_dense_2_loss: 3.8199 - val_dense_4_loss: 3.1417 - val_dense_6_loss: 3.0456 - val_dense_8_loss: 3.0562 - val_dense_10_loss: 3.2457 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1082 - val_dense_6_acc: 0.1340 - val_dense_8_acc: 0.1134 - val_dense_10_acc: 0.0515\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 15.0599 - dense_2_loss: 2.8493 - dense_4_loss: 3.0213 - dense_6_loss: 3.0012 - dense_8_loss: 3.0061 - dense_10_loss: 3.1820 - dense_2_acc: 0.1173 - dense_4_acc: 0.1198 - dense_6_acc: 0.1082 - dense_8_acc: 0.0838 - dense_10_acc: 0.0606 - val_loss: 16.1400 - val_dense_2_loss: 4.0240 - val_dense_4_loss: 2.9851 - val_dense_6_loss: 2.9834 - val_dense_8_loss: 2.9770 - val_dense_10_loss: 3.1705 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.0979 - val_dense_6_acc: 0.2113 - val_dense_8_acc: 0.1753 - val_dense_10_acc: 0.0670\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 14.4344 - dense_2_loss: 2.6882 - dense_4_loss: 2.8539 - dense_6_loss: 2.9277 - dense_8_loss: 2.8823 - dense_10_loss: 3.0823 - dense_2_acc: 0.1688 - dense_4_acc: 0.1430 - dense_6_acc: 0.1405 - dense_8_acc: 0.1044 - dense_10_acc: 0.0838 - val_loss: 16.9801 - val_dense_2_loss: 3.9398 - val_dense_4_loss: 3.1069 - val_dense_6_loss: 3.2597 - val_dense_8_loss: 3.0992 - val_dense_10_loss: 3.5745 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1134 - val_dense_6_acc: 0.1186 - val_dense_8_acc: 0.0928 - val_dense_10_acc: 0.0567\n",
      "Epoch 5/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 13.9220 - dense_2_loss: 2.5516 - dense_4_loss: 2.7616 - dense_6_loss: 2.8377 - dense_8_loss: 2.7983 - dense_10_loss: 2.9728 - dense_2_acc: 0.2229 - dense_4_acc: 0.1572 - dense_6_acc: 0.1430 - dense_8_acc: 0.1289 - dense_10_acc: 0.0838 - val_loss: 15.9106 - val_dense_2_loss: 4.3160 - val_dense_4_loss: 2.8252 - val_dense_6_loss: 2.8902 - val_dense_8_loss: 2.8216 - val_dense_10_loss: 3.0577 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1134 - val_dense_6_acc: 0.1546 - val_dense_8_acc: 0.1701 - val_dense_10_acc: 0.1134\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 13.3804 - dense_2_loss: 2.3667 - dense_4_loss: 2.6624 - dense_6_loss: 2.7692 - dense_8_loss: 2.6768 - dense_10_loss: 2.9053 - dense_2_acc: 0.2126 - dense_4_acc: 0.1624 - dense_6_acc: 0.1675 - dense_8_acc: 0.1598 - dense_10_acc: 0.0979 - val_loss: 17.0228 - val_dense_2_loss: 5.9029 - val_dense_4_loss: 2.6024 - val_dense_6_loss: 2.8541 - val_dense_8_loss: 2.7297 - val_dense_10_loss: 2.9337 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.0876 - val_dense_6_acc: 0.1186 - val_dense_8_acc: 0.2268 - val_dense_10_acc: 0.0928\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 12.8429 - dense_2_loss: 2.1770 - dense_4_loss: 2.5601 - dense_6_loss: 2.6877 - dense_8_loss: 2.5872 - dense_10_loss: 2.8309 - dense_2_acc: 0.2874 - dense_4_acc: 0.1714 - dense_6_acc: 0.1469 - dense_8_acc: 0.1688 - dense_10_acc: 0.1108 - val_loss: 17.3886 - val_dense_2_loss: 7.0663 - val_dense_4_loss: 2.4287 - val_dense_6_loss: 2.6479 - val_dense_8_loss: 2.4652 - val_dense_10_loss: 2.7805 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1031 - val_dense_6_acc: 0.2062 - val_dense_8_acc: 0.2216 - val_dense_10_acc: 0.1495\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 12.4041 - dense_2_loss: 2.0246 - dense_4_loss: 2.4519 - dense_6_loss: 2.6165 - dense_8_loss: 2.5357 - dense_10_loss: 2.7754 - dense_2_acc: 0.3312 - dense_4_acc: 0.1778 - dense_6_acc: 0.1894 - dense_8_acc: 0.1508 - dense_10_acc: 0.1160 - val_loss: 17.2073 - val_dense_2_loss: 7.0519 - val_dense_4_loss: 2.3329 - val_dense_6_loss: 2.5951 - val_dense_8_loss: 2.4726 - val_dense_10_loss: 2.7547 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1443 - val_dense_6_acc: 0.1907 - val_dense_8_acc: 0.2062 - val_dense_10_acc: 0.1804\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 11.8061 - dense_2_loss: 1.7962 - dense_4_loss: 2.2806 - dense_6_loss: 2.5350 - dense_8_loss: 2.4654 - dense_10_loss: 2.7290 - dense_2_acc: 0.4175 - dense_4_acc: 0.1778 - dense_6_acc: 0.2049 - dense_8_acc: 0.1585 - dense_10_acc: 0.1327 - val_loss: 17.4921 - val_dense_2_loss: 7.4178 - val_dense_4_loss: 2.2611 - val_dense_6_loss: 2.6411 - val_dense_8_loss: 2.4164 - val_dense_10_loss: 2.7557 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1443 - val_dense_6_acc: 0.1701 - val_dense_8_acc: 0.2165 - val_dense_10_acc: 0.1340\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 11.1109 - dense_2_loss: 1.6042 - dense_4_loss: 2.1429 - dense_6_loss: 2.4395 - dense_8_loss: 2.2939 - dense_10_loss: 2.6303 - dense_2_acc: 0.4845 - dense_4_acc: 0.1946 - dense_6_acc: 0.1959 - dense_8_acc: 0.2075 - dense_10_acc: 0.1804 - val_loss: 18.0572 - val_dense_2_loss: 8.6621 - val_dense_4_loss: 2.0368 - val_dense_6_loss: 2.4433 - val_dense_8_loss: 2.3072 - val_dense_10_loss: 2.6079 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.1392 - val_dense_6_acc: 0.1907 - val_dense_8_acc: 0.2268 - val_dense_10_acc: 0.2165\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 10.5480 - dense_2_loss: 1.4039 - dense_4_loss: 2.0031 - dense_6_loss: 2.3390 - dense_8_loss: 2.2258 - dense_10_loss: 2.5762 - dense_2_acc: 0.5412 - dense_4_acc: 0.2281 - dense_6_acc: 0.2075 - dense_8_acc: 0.2178 - dense_10_acc: 0.1662 - val_loss: 18.0742 - val_dense_2_loss: 9.1670 - val_dense_4_loss: 1.8822 - val_dense_6_loss: 2.3772 - val_dense_8_loss: 2.1241 - val_dense_10_loss: 2.5236 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.2887 - val_dense_6_acc: 0.2113 - val_dense_8_acc: 0.2835 - val_dense_10_acc: 0.2577\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 9.7555 - dense_2_loss: 1.1189 - dense_4_loss: 1.8417 - dense_6_loss: 2.2174 - dense_8_loss: 2.1209 - dense_10_loss: 2.4567 - dense_2_acc: 0.6314 - dense_4_acc: 0.2255 - dense_6_acc: 0.2706 - dense_8_acc: 0.2436 - dense_10_acc: 0.1881 - val_loss: 18.3473 - val_dense_2_loss: 10.1133 - val_dense_4_loss: 1.6658 - val_dense_6_loss: 2.2459 - val_dense_8_loss: 1.9900 - val_dense_10_loss: 2.3322 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.3041 - val_dense_6_acc: 0.2680 - val_dense_8_acc: 0.3144 - val_dense_10_acc: 0.2423\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 9.0433 - dense_2_loss: 1.0564 - dense_4_loss: 1.6776 - dense_6_loss: 2.0459 - dense_8_loss: 1.9171 - dense_10_loss: 2.3463 - dense_2_acc: 0.6443 - dense_4_acc: 0.2977 - dense_6_acc: 0.3260 - dense_8_acc: 0.2951 - dense_10_acc: 0.1869 - val_loss: 17.0437 - val_dense_2_loss: 9.6904 - val_dense_4_loss: 1.4388 - val_dense_6_loss: 1.9310 - val_dense_8_loss: 1.7942 - val_dense_10_loss: 2.1893 - val_dense_2_acc: 0.0464 - val_dense_4_acc: 0.5052 - val_dense_6_acc: 0.4433 - val_dense_8_acc: 0.3918 - val_dense_10_acc: 0.2320\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 8.3708 - dense_2_loss: 0.7836 - dense_4_loss: 1.5401 - dense_6_loss: 1.9015 - dense_8_loss: 1.8718 - dense_10_loss: 2.2739 - dense_2_acc: 0.7564 - dense_4_acc: 0.4111 - dense_6_acc: 0.3647 - dense_8_acc: 0.3235 - dense_10_acc: 0.1830 - val_loss: 16.6754 - val_dense_2_loss: 9.9101 - val_dense_4_loss: 1.2837 - val_dense_6_loss: 1.8439 - val_dense_8_loss: 1.6227 - val_dense_10_loss: 2.0150 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.6598 - val_dense_6_acc: 0.5309 - val_dense_8_acc: 0.5052 - val_dense_10_acc: 0.2629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 7.6452 - dense_2_loss: 0.7367 - dense_4_loss: 1.4023 - dense_6_loss: 1.7178 - dense_8_loss: 1.6708 - dense_10_loss: 2.1177 - dense_2_acc: 0.7320 - dense_4_acc: 0.4523 - dense_6_acc: 0.4613 - dense_8_acc: 0.4265 - dense_10_acc: 0.1920 - val_loss: 16.2750 - val_dense_2_loss: 10.1880 - val_dense_4_loss: 1.1899 - val_dense_6_loss: 1.5487 - val_dense_8_loss: 1.4848 - val_dense_10_loss: 1.8637 - val_dense_2_acc: 0.0000e+00 - val_dense_4_acc: 0.7216 - val_dense_6_acc: 0.6237 - val_dense_8_acc: 0.5309 - val_dense_10_acc: 0.2577\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 6.9988 - dense_2_loss: 0.6564 - dense_4_loss: 1.3045 - dense_6_loss: 1.5254 - dense_8_loss: 1.5606 - dense_10_loss: 1.9520 - dense_2_acc: 0.7835 - dense_4_acc: 0.4729 - dense_6_acc: 0.5039 - dense_8_acc: 0.4356 - dense_10_acc: 0.2448 - val_loss: 15.4142 - val_dense_2_loss: 9.7846 - val_dense_4_loss: 1.0621 - val_dense_6_loss: 1.3073 - val_dense_8_loss: 1.4994 - val_dense_10_loss: 1.7609 - val_dense_2_acc: 0.0773 - val_dense_4_acc: 0.7371 - val_dense_6_acc: 0.6340 - val_dense_8_acc: 0.5619 - val_dense_10_acc: 0.3866\n",
      "Epoch 17/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 6.8027 - dense_2_loss: 0.6555 - dense_4_loss: 1.2662 - dense_6_loss: 1.4564 - dense_8_loss: 1.4900 - dense_10_loss: 1.9346 - dense_2_acc: 0.7719 - dense_4_acc: 0.5219 - dense_6_acc: 0.5026 - dense_8_acc: 0.4665 - dense_10_acc: 0.2912 - val_loss: 17.0032 - val_dense_2_loss: 11.3305 - val_dense_4_loss: 1.0308 - val_dense_6_loss: 1.5311 - val_dense_8_loss: 1.3766 - val_dense_10_loss: 1.7342 - val_dense_2_acc: 0.0052 - val_dense_4_acc: 0.7629 - val_dense_6_acc: 0.6546 - val_dense_8_acc: 0.5825 - val_dense_10_acc: 0.3196\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 6.1515 - dense_2_loss: 0.5377 - dense_4_loss: 1.1636 - dense_6_loss: 1.2349 - dense_8_loss: 1.3885 - dense_10_loss: 1.8268 - dense_2_acc: 0.7964 - dense_4_acc: 0.5567 - dense_6_acc: 0.5722 - dense_8_acc: 0.5064 - dense_10_acc: 0.3235 - val_loss: 14.8449 - val_dense_2_loss: 9.7106 - val_dense_4_loss: 0.9866 - val_dense_6_loss: 1.2512 - val_dense_8_loss: 1.3022 - val_dense_10_loss: 1.5943 - val_dense_2_acc: 0.0155 - val_dense_4_acc: 0.7835 - val_dense_6_acc: 0.7474 - val_dense_8_acc: 0.6546 - val_dense_10_acc: 0.5155\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 5.5958 - dense_2_loss: 0.4730 - dense_4_loss: 1.0737 - dense_6_loss: 1.1412 - dense_8_loss: 1.2383 - dense_10_loss: 1.6696 - dense_2_acc: 0.8170 - dense_4_acc: 0.5683 - dense_6_acc: 0.6070 - dense_8_acc: 0.5515 - dense_10_acc: 0.3827 - val_loss: 14.9051 - val_dense_2_loss: 10.1727 - val_dense_4_loss: 0.9265 - val_dense_6_loss: 1.0979 - val_dense_8_loss: 1.2562 - val_dense_10_loss: 1.4517 - val_dense_2_acc: 0.0670 - val_dense_4_acc: 0.7938 - val_dense_6_acc: 0.7165 - val_dense_8_acc: 0.6804 - val_dense_10_acc: 0.5206\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 5.2334 - dense_2_loss: 0.4250 - dense_4_loss: 0.9635 - dense_6_loss: 1.0809 - dense_8_loss: 1.1829 - dense_10_loss: 1.5811 - dense_2_acc: 0.8402 - dense_4_acc: 0.6211 - dense_6_acc: 0.6263 - dense_8_acc: 0.5825 - dense_10_acc: 0.4240 - val_loss: 14.1646 - val_dense_2_loss: 9.7627 - val_dense_4_loss: 0.9039 - val_dense_6_loss: 1.0654 - val_dense_8_loss: 1.1865 - val_dense_10_loss: 1.2461 - val_dense_2_acc: 0.0773 - val_dense_4_acc: 0.7938 - val_dense_6_acc: 0.7320 - val_dense_8_acc: 0.6804 - val_dense_10_acc: 0.6546\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 4.9428 - dense_2_loss: 0.4519 - dense_4_loss: 0.9489 - dense_6_loss: 0.9662 - dense_8_loss: 1.1444 - dense_10_loss: 1.4315 - dense_2_acc: 0.8299 - dense_4_acc: 0.6443 - dense_6_acc: 0.6482 - dense_8_acc: 0.5876 - dense_10_acc: 0.4356 - val_loss: 14.7358 - val_dense_2_loss: 10.6779 - val_dense_4_loss: 0.8055 - val_dense_6_loss: 1.1219 - val_dense_8_loss: 1.0210 - val_dense_10_loss: 1.1095 - val_dense_2_acc: 0.0361 - val_dense_4_acc: 0.7938 - val_dense_6_acc: 0.7423 - val_dense_8_acc: 0.7577 - val_dense_10_acc: 0.6856\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 4.7371 - dense_2_loss: 0.4060 - dense_4_loss: 0.8966 - dense_6_loss: 0.9637 - dense_8_loss: 1.0753 - dense_10_loss: 1.3956 - dense_2_acc: 0.8582 - dense_4_acc: 0.6482 - dense_6_acc: 0.6456 - dense_8_acc: 0.6018 - dense_10_acc: 0.4485 - val_loss: 14.9314 - val_dense_2_loss: 10.7618 - val_dense_4_loss: 0.9306 - val_dense_6_loss: 1.1278 - val_dense_8_loss: 1.0529 - val_dense_10_loss: 1.0583 - val_dense_2_acc: 0.0206 - val_dense_4_acc: 0.7887 - val_dense_6_acc: 0.7320 - val_dense_8_acc: 0.7629 - val_dense_10_acc: 0.6856\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 4.2769 - dense_2_loss: 0.3712 - dense_4_loss: 0.9282 - dense_6_loss: 0.8284 - dense_8_loss: 0.9055 - dense_10_loss: 1.2434 - dense_2_acc: 0.8557 - dense_4_acc: 0.6224 - dense_6_acc: 0.6843 - dense_8_acc: 0.6637 - dense_10_acc: 0.5271 - val_loss: 13.2682 - val_dense_2_loss: 9.2335 - val_dense_4_loss: 0.9190 - val_dense_6_loss: 0.9738 - val_dense_8_loss: 1.0688 - val_dense_10_loss: 1.0732 - val_dense_2_acc: 0.1134 - val_dense_4_acc: 0.7835 - val_dense_6_acc: 0.7577 - val_dense_8_acc: 0.7165 - val_dense_10_acc: 0.6959\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 2s 2ms/step - loss: 4.1721 - dense_2_loss: 0.3819 - dense_4_loss: 0.8488 - dense_6_loss: 0.8520 - dense_8_loss: 0.8510 - dense_10_loss: 1.2384 - dense_2_acc: 0.8621 - dense_4_acc: 0.6598 - dense_6_acc: 0.6740 - dense_8_acc: 0.6920 - dense_10_acc: 0.5464 - val_loss: 14.2216 - val_dense_2_loss: 10.3952 - val_dense_4_loss: 0.9954 - val_dense_6_loss: 0.9833 - val_dense_8_loss: 0.9143 - val_dense_10_loss: 0.9333 - val_dense_2_acc: 0.0567 - val_dense_4_acc: 0.7887 - val_dense_6_acc: 0.7680 - val_dense_8_acc: 0.7526 - val_dense_10_acc: 0.6959\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 4.0268 - dense_2_loss: 0.3647 - dense_4_loss: 0.8212 - dense_6_loss: 0.8072 - dense_8_loss: 0.9000 - dense_10_loss: 1.1338 - dense_2_acc: 0.8673 - dense_4_acc: 0.6701 - dense_6_acc: 0.7075 - dense_8_acc: 0.6534 - dense_10_acc: 0.5696 - val_loss: 14.0223 - val_dense_2_loss: 9.9599 - val_dense_4_loss: 0.9511 - val_dense_6_loss: 1.0463 - val_dense_8_loss: 1.0716 - val_dense_10_loss: 0.9934 - val_dense_2_acc: 0.0722 - val_dense_4_acc: 0.7887 - val_dense_6_acc: 0.7474 - val_dense_8_acc: 0.7216 - val_dense_10_acc: 0.6959\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 3.8842 - dense_2_loss: 0.3163 - dense_4_loss: 0.8286 - dense_6_loss: 0.7781 - dense_8_loss: 0.8308 - dense_10_loss: 1.1304 - dense_2_acc: 0.8789 - dense_4_acc: 0.6611 - dense_6_acc: 0.6920 - dense_8_acc: 0.6856 - dense_10_acc: 0.5657 - val_loss: 15.0210 - val_dense_2_loss: 11.0557 - val_dense_4_loss: 0.8914 - val_dense_6_loss: 0.9860 - val_dense_8_loss: 1.0229 - val_dense_10_loss: 1.0650 - val_dense_2_acc: 0.0412 - val_dense_4_acc: 0.8196 - val_dense_6_acc: 0.7629 - val_dense_8_acc: 0.7423 - val_dense_10_acc: 0.6907\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 3.5097 - dense_2_loss: 0.2691 - dense_4_loss: 0.7240 - dense_6_loss: 0.7322 - dense_8_loss: 0.7620 - dense_10_loss: 1.0224 - dense_2_acc: 0.8995 - dense_4_acc: 0.6959 - dense_6_acc: 0.7010 - dense_8_acc: 0.7010 - dense_10_acc: 0.6095 - val_loss: 13.5251 - val_dense_2_loss: 9.7076 - val_dense_4_loss: 0.9274 - val_dense_6_loss: 0.9551 - val_dense_8_loss: 1.0191 - val_dense_10_loss: 0.9160 - val_dense_2_acc: 0.1082 - val_dense_4_acc: 0.8144 - val_dense_6_acc: 0.7526 - val_dense_8_acc: 0.7371 - val_dense_10_acc: 0.7371\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 3.3749 - dense_2_loss: 0.2711 - dense_4_loss: 0.7069 - dense_6_loss: 0.6893 - dense_8_loss: 0.7212 - dense_10_loss: 0.9865 - dense_2_acc: 0.8943 - dense_4_acc: 0.6959 - dense_6_acc: 0.7191 - dense_8_acc: 0.7320 - dense_10_acc: 0.6121 - val_loss: 14.0510 - val_dense_2_loss: 10.3905 - val_dense_4_loss: 0.8396 - val_dense_6_loss: 0.9479 - val_dense_8_loss: 0.9472 - val_dense_10_loss: 0.9257 - val_dense_2_acc: 0.0567 - val_dense_4_acc: 0.7990 - val_dense_6_acc: 0.7990 - val_dense_8_acc: 0.7526 - val_dense_10_acc: 0.7320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 3.3928 - dense_2_loss: 0.2846 - dense_4_loss: 0.7431 - dense_6_loss: 0.6660 - dense_8_loss: 0.7263 - dense_10_loss: 0.9727 - dense_2_acc: 0.8879 - dense_4_acc: 0.6933 - dense_6_acc: 0.7500 - dense_8_acc: 0.7165 - dense_10_acc: 0.6134 - val_loss: 13.8926 - val_dense_2_loss: 10.0323 - val_dense_4_loss: 0.8914 - val_dense_6_loss: 1.1930 - val_dense_8_loss: 0.9188 - val_dense_10_loss: 0.8572 - val_dense_2_acc: 0.0979 - val_dense_4_acc: 0.8196 - val_dense_6_acc: 0.7268 - val_dense_8_acc: 0.7474 - val_dense_10_acc: 0.7784\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 1s 2ms/step - loss: 3.2076 - dense_2_loss: 0.2690 - dense_4_loss: 0.6825 - dense_6_loss: 0.6426 - dense_8_loss: 0.6786 - dense_10_loss: 0.9348 - dense_2_acc: 0.8956 - dense_4_acc: 0.7294 - dense_6_acc: 0.7397 - dense_8_acc: 0.7204 - dense_10_acc: 0.6482 - val_loss: 14.2322 - val_dense_2_loss: 10.3638 - val_dense_4_loss: 0.9613 - val_dense_6_loss: 1.0140 - val_dense_8_loss: 0.9346 - val_dense_10_loss: 0.9585 - val_dense_2_acc: 0.0722 - val_dense_4_acc: 0.8196 - val_dense_6_acc: 0.7680 - val_dense_8_acc: 0.7526 - val_dense_10_acc: 0.7577\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# later...\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = img / 255.0\n",
    "    else:\n",
    "        print(\"Not detected\");\n",
    "    res = np.array(loaded_model.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 36))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        #probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += symbols[l]\n",
    "    return print(\"Result:\",capt)#, sum(probs) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfiglet import Figlet\n",
    "def cli_test():\n",
    "    f = Figlet(font='slant')\n",
    "    print(f.renderText('Captcha???? Hold My Beer!!'))\n",
    "    file = input(\"Get the Captcha!=\")\n",
    "    print(predict(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ______            __       __         ___  ___  ___  ___ \n",
      "  / ____/___ _____  / /______/ /_  ____ /__ \\/__ \\/__ \\/__ \\\n",
      " / /   / __ `/ __ \\/ __/ ___/ __ \\/ __ `// _/ / _/ / _/ / _/\n",
      "/ /___/ /_/ / /_/ / /_/ /__/ / / / /_/ //_/  /_/  /_/  /_/  \n",
      "\\____/\\__,_/ .___/\\__/\\___/_/ /_/\\__,_/(_)  (_)  (_)  (_)   \n",
      "          /_/                                               \n",
      "    __  __      __    __   __  ___         ____                 ____\n",
      "   / / / /___  / /___/ /  /  |/  /_  __   / __ )___  ___  _____/ / /\n",
      "  / /_/ / __ \\/ / __  /  / /|_/ / / / /  / __  / _ \\/ _ \\/ ___/ / / \n",
      " / __  / /_/ / / /_/ /  / /  / / /_/ /  / /_/ /  __/  __/ /  /_/_/  \n",
      "/_/ /_/\\____/_/\\__,_/  /_/  /_/\\__, /  /_____/\\___/\\___/_/  (_|_)   \n",
      "                              /____/                                \n",
      "\n",
      "Get the Captcha!=test3.png\n",
      "Result: gnbn4\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cli_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensor_test] *",
   "language": "python",
   "name": "conda-env-.conda-tensor_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
